{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Instance Segmentation - YOLOv11 Training\n",
                "Fine-tune YOLOv11-seg for instance segmentation using Apple Silicon (MPS) or CUDA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install ultralytics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "from ultralytics import YOLO\n",
                "import torch\n",
                "\n",
                "print(f'PyTorch: {torch.__version__}')\n",
                "print(f'MPS available: {torch.backends.mps.is_available()}')\n",
                "print(f'CUDA available: {torch.cuda.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset path (YOLOv8/v11 segmentation format with data.yaml)\n",
                "# Labels should be: <class_id> <x1> <y1> <x2> <y2> ... <xn> <yn> (normalized polygon coords)\n",
                "DATA_YAML = '<path_to_data.yaml>'\n",
                "\n",
                "# Output directory for trained model\n",
                "OUTPUT_DIR = './checkpoints/yolo11s_seg'\n",
                "\n",
                "# Model variant (segmentation models end with -seg)\n",
                "# yolo11n-seg (nano), yolo11s-seg (small), yolo11m-seg (medium), yolo11l-seg (large)\n",
                "MODEL = 'yolo11s-seg.pt'  # small - good balance of speed and accuracy\n",
                "\n",
                "# Training parameters\n",
                "EPOCHS = 100\n",
                "BATCH_SIZE = 8  # lower batch for segmentation (more memory intensive)\n",
                "IMG_SIZE = 640  # input resolution\n",
                "PATIENCE = 15   # early stopping patience\n",
                "\n",
                "# Device selection\n",
                "if torch.backends.mps.is_available():\n",
                "    DEVICE = 'mps'\n",
                "elif torch.cuda.is_available():\n",
                "    DEVICE = 0  # cuda device id\n",
                "else:\n",
                "    DEVICE = 'cpu'\n",
                "\n",
                "print(f'Device: {DEVICE}')\n",
                "print(f'Model: {MODEL}')\n",
                "print(f'Epochs: {EPOCHS}')\n",
                "print(f'Batch size: {BATCH_SIZE}')\n",
                "print(f'Image size: {IMG_SIZE}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained YOLOv11-seg\n",
                "model = YOLO(MODEL)\n",
                "print(f'Loaded {MODEL}')\n",
                "print(f'Task: {model.task}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the segmentation model\n",
                "results = model.train(\n",
                "    data=DATA_YAML,\n",
                "    epochs=EPOCHS,\n",
                "    batch=BATCH_SIZE,\n",
                "    imgsz=IMG_SIZE,\n",
                "    device=DEVICE,\n",
                "    patience=PATIENCE,\n",
                "    project=OUTPUT_DIR,\n",
                "    name='train',\n",
                "    exist_ok=True,\n",
                "    pretrained=True,\n",
                "    optimizer='AdamW',\n",
                "    lr0=0.001,\n",
                "    lrf=0.01,\n",
                "    warmup_epochs=3,\n",
                "    close_mosaic=10,\n",
                "    plots=True,\n",
                "    save=True,\n",
                "    val=True,\n",
                "    mask_ratio=4,  # mask downsample ratio\n",
                "    overlap_mask=True,  # overlap masks during training\n",
                ")\n",
                "\n",
                "print('\\nTraining complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluate on Validation Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best checkpoint and validate\n",
                "best_model = YOLO(f'{OUTPUT_DIR}/train/weights/best.pt')\n",
                "val_results = best_model.val(data=DATA_YAML)\n",
                "\n",
                "# Box metrics\n",
                "print(f\"\\nBox mAP50: {val_results.box.map50:.4f}\")\n",
                "print(f\"Box mAP50-95: {val_results.box.map:.4f}\")\n",
                "\n",
                "# Mask metrics\n",
                "print(f\"\\nMask mAP50: {val_results.seg.map50:.4f}\")\n",
                "print(f\"Mask mAP50-95: {val_results.seg.map:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Single Image Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "from IPython.display import display, Image\n",
                "import tempfile\n",
                "\n",
                "def predict_and_display(model, image_path, conf=0.5):\n",
                "    \"\"\"Run segmentation inference and display results.\"\"\"\n",
                "    results = model.predict(image_path, conf=conf)\n",
                "    \n",
                "    # Get annotated image with masks\n",
                "    annotated = results[0].plot()\n",
                "    \n",
                "    # Save to temp file and display\n",
                "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as f:\n",
                "        cv2.imwrite(f.name, annotated)\n",
                "        display(Image(filename=f.name))\n",
                "    \n",
                "    # Print detections\n",
                "    if results[0].masks is not None:\n",
                "        print(f'Found {len(results[0].masks)} objects')\n",
                "        for i, (box, mask) in enumerate(zip(results[0].boxes, results[0].masks)):\n",
                "            cls = int(box.cls)\n",
                "            conf = float(box.conf)\n",
                "            name = results[0].names[cls]\n",
                "            print(f'  {i+1}. {name}: {conf:.2f}')\n",
                "    else:\n",
                "        print('No objects detected')\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on a single image\n",
                "# predict_and_display(best_model, '/path/to/test/image.jpg', conf=0.5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Video Inference with Segmentation Masks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import time\n",
                "\n",
                "def process_video_segmentation(model, input_path, output_path, conf=0.5, display=False):\n",
                "    \"\"\"Process video with segmentation model, drawing masks.\"\"\"\n",
                "    cap = cv2.VideoCapture(input_path)\n",
                "    \n",
                "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
                "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "    \n",
                "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
                "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
                "    \n",
                "    print(f'Processing: {width}x{height} @ {fps:.1f} fps ({total_frames} frames)')\n",
                "    \n",
                "    frame_count = 0\n",
                "    total_time = 0\n",
                "    \n",
                "    while True:\n",
                "        ret, frame = cap.read()\n",
                "        if not ret:\n",
                "            break\n",
                "        \n",
                "        # Predict with segmentation\n",
                "        start = time.time()\n",
                "        results = model.predict(frame, conf=conf, verbose=False)\n",
                "        total_time += time.time() - start\n",
                "        \n",
                "        # Draw results (includes masks)\n",
                "        annotated = results[0].plot()\n",
                "        out.write(annotated)\n",
                "        frame_count += 1\n",
                "        \n",
                "        if frame_count % 100 == 0:\n",
                "            avg_fps = frame_count / total_time\n",
                "            print(f'Progress: {frame_count}/{total_frames} ({avg_fps:.1f} FPS)')\n",
                "        \n",
                "        if display:\n",
                "            cv2.imshow('Segmentation Output', annotated)\n",
                "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
                "                break\n",
                "    \n",
                "    cap.release()\n",
                "    out.release()\n",
                "    if display:\n",
                "        cv2.destroyAllWindows()\n",
                "    \n",
                "    avg_fps = frame_count / total_time\n",
                "    print(f'\\nDone. Saved to {output_path}')\n",
                "    print(f'Average inference: {avg_fps:.1f} FPS ({1000/avg_fps:.1f}ms per frame)')\n",
                "    return frame_count"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Process a video (update paths)\n",
                "# process_video_segmentation(\n",
                "#     best_model,\n",
                "#     input_path='/path/to/input.mp4',\n",
                "#     output_path='/path/to/output_seg.mp4',\n",
                "#     conf=0.5,\n",
                "#     display=True\n",
                "# )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to various formats\n",
                "# best_model.export(format='onnx')  # ONNX\n",
                "# best_model.export(format='coreml')  # CoreML for iOS/macOS\n",
                "# best_model.export(format='engine')  # TensorRT for NVIDIA GPUs"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}