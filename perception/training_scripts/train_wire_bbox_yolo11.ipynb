{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Wire Bounding Box Detection - YOLOv11 Training\n",
                "Fine-tune YOLOv11s for wire detection using Apple Silicon (MPS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install ultralytics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "from ultralytics import YOLO\n",
                "import torch\n",
                "\n",
                "print(f'PyTorch: {torch.__version__}')\n",
                "print(f'MPS available: {torch.backends.mps.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset path (YOLO format with data.yaml)\n",
                "DATA_YAML = '<path_to_data>'\n",
                "\n",
                "# Output directory for trained model\n",
                "OUTPUT_DIR = './checkpoints/yolo11s_wires'\n",
                "\n",
                "# Model variant: yolo11n (nano), yolo11s (small), yolo11m (medium)\n",
                "MODEL = 'yolo11s.pt'  # small - good balance for wire detection\n",
                "\n",
                "# Training parameters\n",
                "EPOCHS = 50\n",
                "BATCH_SIZE = 16\n",
                "IMG_SIZE = 640  # input resolution\n",
                "PATIENCE = 10   # early stopping patience\n",
                "\n",
                "# Device\n",
                "if torch.backends.mps.is_available():\n",
                "    DEVICE = 'mps'\n",
                "elif torch.cuda.is_available():\n",
                "    DEVICE = 0  # cuda device id\n",
                "else:\n",
                "    DEVICE = 'cpu'\n",
                "\n",
                "print(f'Device: {DEVICE}')\n",
                "print(f'Model: {MODEL}')\n",
                "print(f'Epochs: {EPOCHS}')\n",
                "print(f'Batch size: {BATCH_SIZE}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained YOLOv11\n",
                "model = YOLO(MODEL)\n",
                "print(f'Loaded {MODEL}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "results = model.train(\n",
                "    data=DATA_YAML,\n",
                "    epochs=EPOCHS,\n",
                "    batch=BATCH_SIZE,\n",
                "    imgsz=IMG_SIZE,\n",
                "    device=DEVICE,\n",
                "    patience=PATIENCE,\n",
                "    project=OUTPUT_DIR,\n",
                "    name='train',\n",
                "    exist_ok=True,\n",
                "    pretrained=True,\n",
                "    optimizer='AdamW',\n",
                "    lr0=0.001,\n",
                "    lrf=0.01,\n",
                "    warmup_epochs=3,\n",
                "    close_mosaic=10,\n",
                "    plots=True,\n",
                "    save=True,\n",
                "    val=True,\n",
                ")\n",
                "\n",
                "print('\\nTraining complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluate on Validation Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best checkpoint and validate\n",
                "best_model = YOLO(f'{OUTPUT_DIR}/train/weights/best.pt')\n",
                "val_results = best_model.val(data=DATA_YAML)\n",
                "\n",
                "print(f\"\\nmAP50: {val_results.box.map50:.4f}\")\n",
                "print(f\"mAP50-95: {val_results.box.map:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Video Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import time\n",
                "\n",
                "def process_video(model, input_path, output_path, conf=0.5, display=False):\n",
                "    \"\"\"Process video with trained model.\"\"\"\n",
                "    cap = cv2.VideoCapture(input_path)\n",
                "    \n",
                "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
                "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
                "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
                "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
                "    \n",
                "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
                "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
                "    \n",
                "    print(f'Processing: {width}x{height} @ {fps:.1f} fps ({total_frames} frames)')\n",
                "    \n",
                "    frame_count = 0\n",
                "    total_time = 0\n",
                "    \n",
                "    while True:\n",
                "        ret, frame = cap.read()\n",
                "        if not ret:\n",
                "            break\n",
                "        \n",
                "        # Predict\n",
                "        start = time.time()\n",
                "        results = model.predict(frame, conf=conf, verbose=False)\n",
                "        total_time += time.time() - start\n",
                "        \n",
                "        # Draw results\n",
                "        annotated = results[0].plot()\n",
                "        out.write(annotated)\n",
                "        frame_count += 1\n",
                "        \n",
                "        if frame_count % 100 == 0:\n",
                "            avg_fps = frame_count / total_time\n",
                "            print(f'Progress: {frame_count}/{total_frames} ({avg_fps:.1f} FPS)')\n",
                "        \n",
                "        if display:\n",
                "            cv2.imshow('Output', annotated)\n",
                "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
                "                break\n",
                "    \n",
                "    cap.release()\n",
                "    out.release()\n",
                "    if display:\n",
                "        cv2.destroyAllWindows()\n",
                "    \n",
                "    avg_fps = frame_count / total_time\n",
                "    print(f'\\nDone. Saved to {output_path}')\n",
                "    print(f'Average inference: {avg_fps:.1f} FPS ({1000/avg_fps:.1f}ms per frame)')\n",
                "    return frame_count"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Process a video (update paths)\n",
                "# process_video(\n",
                "#     best_model,\n",
                "#     input_path='/path/to/input.mp4',\n",
                "#     output_path='/path/to/output.mp4',\n",
                "#     conf=0.5,\n",
                "#     display=True\n",
                "# )"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
