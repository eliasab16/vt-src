{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wire Color Detection - MobileNetV2 Training\n",
    "Train a small CNN to classify wire colors: white, red, green, yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '<data_dir>'\n",
    "OUTPUT_DIR = './checkpoints'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Color classes must match folder names\n",
    "CLASSES = ['green', 'red', 'white', 'yellow']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using MPS (Apple Silicon)')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n",
    "    transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Expected folder structure:\n",
    "```\n",
    "DATA_DIR/\n",
    "  train/\n",
    "    green/\n",
    "    red/\n",
    "    white/\n",
    "    yellow/\n",
    "  valid/\n",
    "    green/\n",
    "    red/\n",
    "    white/\n",
    "    yellow/\n",
    "  test/\n",
    "    green/\n",
    "    red/\n",
    "    white/\n",
    "    yellow/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path(DATA_DIR) / 'train'\n",
    "valid_dir = Path(DATA_DIR) / 'valid'\n",
    "test_dir = Path(DATA_DIR) / 'test'\n",
    "\n",
    "# load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "valid_dataset = datasets.ImageFolder(valid_dir, transform=eval_transform) if valid_dir.exists() else None\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=eval_transform) if test_dir.exists() else None\n",
    "\n",
    "# create data loaders (num_workers=0 works best with MPS)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) if valid_dataset else None\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) if test_dataset else None\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Classes: {train_dataset.classes}')\n",
    "if valid_dataset:\n",
    "    print(f'Validation samples: {len(valid_dataset)}')\n",
    "if test_dataset:\n",
    "    print(f'Test samples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=NUM_CLASSES, pretrained=True):\n",
    "    \"\"\"Create MobileNetV2 model with custom classifier head.\"\"\"\n",
    "    model = models.mobilenet_v2(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "    \n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(num_classes=len(train_dataset.classes))\n",
    "model = model.to(device)\n",
    "print(f'Model created with {sum(p.numel() for p in model.parameters())} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "best_acc = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    \n",
    "    log = f'Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%'\n",
    "    \n",
    "    if valid_loader:\n",
    "        val_loss, val_acc = validate(model, valid_loader, criterion)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        log += f' | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%'\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'accuracy': val_acc,\n",
    "                'classes': train_dataset.classes\n",
    "            }, f'{OUTPUT_DIR}/best_model.pt')\n",
    "            log += ' [BEST]'\n",
    "    \n",
    "    print(log)\n",
    "    scheduler.step()\n",
    "\n",
    "print(f'\\nTraining complete! Best validation accuracy: {best_acc:.2f}%')\n",
    "\n",
    "# evaluate on the test set\n",
    "if test_loader:\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion)\n",
    "    print(f'Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train')\n",
    "if history['val_loss']:\n",
    "    ax1.plot(history['val_loss'], label='Val')\n",
    "ax1.set_title('Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train')\n",
    "if history['val_acc']:\n",
    "    ax2.plot(history['val_acc'], label='Val')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, classes):\n",
    "    \"\"\"Predict color for a single image.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = eval_transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted = probabilities.max(1)\n",
    "    \n",
    "    return {\n",
    "        'class': classes[predicted.item()],\n",
    "        'confidence': confidence.item(),\n",
    "        'probabilities': {c: p.item() for c, p in zip(classes, probabilities[0])}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model and test\n",
    "checkpoint = torch.load(f'{OUTPUT_DIR}/best_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "classes = checkpoint['classes']\n",
    "\n",
    "# Test on an image (change path as needed)\n",
    "result = predict('<path_to_test_image>', model, classes)\n",
    "print(f\"Predicted: {result['class']} ({result['confidence']:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
